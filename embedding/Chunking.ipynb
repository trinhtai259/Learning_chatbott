{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm # thanh trạng thái\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    cleaned_text = cleaned_text.replace(\"÷\",\" đến \")\n",
    "    cleaned_text= re.sub(r'\\.+', '.', cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\":\",\" \")\n",
    "    cleaned_text = cleaned_text.replace(\"<\",\"nhỏ hơn\")\n",
    "    cleaned_text = cleaned_text.replace(\"≥\",\"lớn hơn bằng\")\n",
    "    cleaned_text = cleaned_text.replace(\">\",\"lớn hơn\")\n",
    "    cleaned_text = cleaned_text.replace(\"≤\",\"nhỏ hơn bằng\")\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables_reader(tables):\n",
    "    table_content = []\n",
    "    for table in tables:\n",
    "        if len(table[0]) >= 5:\n",
    "            table = list(map(list, zip(*table)))\n",
    "        titles = table.pop(0)\n",
    "        table_content.append([])\n",
    "        for i in range(len(table)):\n",
    "            for j in range(len(table[i])):\n",
    "                if table[i][j] == None:\n",
    "                    table[i][j] = table[i-1][j]\n",
    "                table[i][j] = titles[j] + \" \" + table[i][j]\n",
    "            \n",
    "            table_content[-1].append(\" \".join(table[i]).replace('\\n',\" \")+\". \")\n",
    "    return table_content\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_and_tables(pdf_path):\n",
    "    text_segments = []\n",
    "    # tables = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            \n",
    "            if page.extract_tables():\n",
    "                page_tables = page.extract_tables()\n",
    "                tables_text = tables_reader(page_tables)\n",
    "                for table in tables_text:\n",
    "                    table_text = \" \".join(table)+\".\"\n",
    "                    text_segments.append(table_text)\n",
    "            \n",
    "            # Trích xuất văn bản\n",
    "            page_text = page.extract_text()\n",
    "            text_segments.append(page_text)\n",
    "\n",
    "        text = \" \".join(text_segments)\n",
    "        return text\n",
    "\n",
    "# text_segments = extract_text_and_tables(pdf_path)\n",
    "\n",
    "# # Kiểm tra\n",
    "# text_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "def split_chunk(input_list: list) -> list[list[str]]:\n",
    "    slice_size = 2\n",
    "    list_sentece = [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "    chunks = []\n",
    "    # print(slice_size)\n",
    "    for chunk in list_sentece:            \n",
    "        chunk = \"\".join(chunk).replace(\"  \", \" \").strip()\n",
    "        if len(chunk) > seq_len:\n",
    "            nlp = spacy.blank(\"vi\")\n",
    "            nlp.add_pipe(\"sentencizer\")\n",
    "            chunk = list(nlp(chunk).sents)\n",
    "            chunk = [str(sentence) for sentence in chunk]\n",
    "            chunks.extend(chunk)\n",
    "        else:\n",
    "            chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_split(texts):\n",
    "    nlp = spacy.blank(\"vi\")\n",
    "    nlp.add_pipe(\"sentencizer\") # Thêm pipeline sentencizer giúp phân đoạn câu\n",
    "    texts = list(nlp(texts).sents) # gán vào pipeline\n",
    "    texts = [str(sentence) for sentence in texts]\n",
    "    for sentence in texts:\n",
    "        if len(sentence) > seq_len:\n",
    "            texts.remove(sentence)\n",
    "            sentence = sentence.replace(\";\", \".\")\n",
    "            sentence = list(nlp(sentence).sents) # gán vào pipeline\n",
    "            for item in sentence:\n",
    "                texts.append(str(item))\n",
    "    texts = split_chunk(texts)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Tách văn bản quy định thành các phần dựa trên từ khóa 'Điều'. --> dễ tìm kiếm hơn\n",
    "def split_regulation(pdf_path: str)-> list[dict]:\n",
    "\n",
    "    pages_and_texts = []\n",
    "    sections=[{'title':\"\",'content':\"\"}]\n",
    "    text = extract_text_and_tables(pdf_path)\n",
    "    cur_main_sec = \"\"\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        # Tìm tiêu đề (dòng đầu tiên)\n",
    "        title_match = re.match(r\"(Điều\\s\\d+\\.)\", line)\n",
    "        \n",
    "        if not title_match:\n",
    "            if cur_main_sec == \"\":\n",
    "                sections[-1]['content'] += line + \" \"\n",
    "            else:\n",
    "                sections[-1]['content'] += \" \" + line   \n",
    "        else:\n",
    "            cur_main_sec = line\n",
    "            sections.append({})\n",
    "            sections[-1]['title'] = cur_main_sec\n",
    "            sections[-1]['content'] = \"\"\n",
    "\n",
    "    for section in sections:\n",
    "            cleaned_content = text_formatter(section['content'])\n",
    "            \n",
    "            len_content = len(cleaned_content)\n",
    "            \n",
    "            if len_content > seq_len:\n",
    "                cleaned_content = sentences_split(cleaned_content)\n",
    "            else:\n",
    "                cleaned_content = [cleaned_content]\n",
    "            for i in range (len(cleaned_content)):\n",
    "                pages_and_texts.append({\"char_count\": len(cleaned_content[i])+len(section['title']),\n",
    "                                        \"token_count\": (len(cleaned_content[i])+len(section['title'])) / 4,  # 1 token = ~4 chars\n",
    "                                        \"text\": f\"{section['title']}\\n {cleaned_content[i]}\"})\n",
    "    return pages_and_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pages_and_texts \u001b[38;5;241m=\u001b[39m split_regulation(pdf_path\u001b[38;5;241m=\u001b[39m\u001b[43mpdf_path\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pdf_path' is not defined"
     ]
    }
   ],
   "source": [
    "pdf_path = \"\"\n",
    "pages_and_texts = split_regulation(pdf_path=pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323</td>\n",
       "      <td>80.75</td>\n",
       "      <td>Điều 46. Quy định chuyển tiếp\\n 1.Đối với các ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>8.25</td>\n",
       "      <td>Điều 46. Quy định chuyển tiếp\\n 2.2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>7.75</td>\n",
       "      <td>Điều 46. Quy định chuyển tiếp\\n 3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491</td>\n",
       "      <td>122.75</td>\n",
       "      <td>Điều 46. Quy định chuyển tiếp\\n Đối với các kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>491</td>\n",
       "      <td>122.75</td>\n",
       "      <td>Điều 46. Quy định chuyển tiếp\\n Đối với các kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>463</td>\n",
       "      <td>115.75</td>\n",
       "      <td>Điều 46. Quy định chuyển tiếp\\n Đối với các kh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  token_count                                               text\n",
       "0           0         0.00                                                \\n \n",
       "1         323        80.75  Điều 46. Quy định chuyển tiếp\\n 1.Đối với các ...\n",
       "2          33         8.25               Điều 46. Quy định chuyển tiếp\\n 2.2.\n",
       "3          31         7.75                 Điều 46. Quy định chuyển tiếp\\n 3.\n",
       "4         491       122.75  Điều 46. Quy định chuyển tiếp\\n Đối với các kh...\n",
       "5         491       122.75  Điều 46. Quy định chuyển tiếp\\n Đối với các kh...\n",
       "6         463       115.75  Điều 46. Quy định chuyển tiếp\\n Đối với các kh..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts_pd = pd.DataFrame(pages_and_texts)\n",
    "pages_and_texts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Đối với các khoá tuyển sinh có quyết định công nhận NCS sau ngày 01 tháng\n",
      "2. Đối với các khoá tuyển sinh có quyết định công nhận NCS trong khoảng thời\n",
      "2. Đối với các khoá tuyển sinh đã có quyết định công nhận NCS trong khoảng\n",
      "3. Đối với các khoá tuyển sinh đã có quyết định công nhận NCS trước ngày 18\n"
     ]
    }
   ],
   "source": [
    "def split_section(file_path):\n",
    "    sections=[{'title':\"\",'content':\"\"}]\n",
    "    text = \"\"\n",
    "    cur_main_sec = \"\"\n",
    "    cur_sub_main_sec = \"\"\n",
    "    cur_sub_sub_main_sec = \"\"\n",
    "    pages_and_texts = []\n",
    "    # Đọc nội dung từ file PDF\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "        \n",
    "        # Tìm các mục bằng regex\n",
    "        for line in text.split('\\n'):\n",
    "            section_match = re.match(r'^([A-Z]+\\.)*((\\d+\\.)(\\d+\\.)?(\\d+\\.)?)',line)\n",
    "            if not section_match:\n",
    "                if cur_main_sec == \"\":\n",
    "                    sections[-1]['content'] += line + \" \"\n",
    "                else:\n",
    "                    sections[-1]['content'] += \" \" + line\n",
    "            elif section_match.group(1):\n",
    "                cur_main_sec = line\n",
    "                sections.append({})\n",
    "                sections[-1]['title'] = cur_main_sec\n",
    "                \n",
    "                sections[-1]['content'] = \"\"\n",
    "            elif section_match.group(5):\n",
    "                cur_sub_sub_main_sec = cur_main_sec +\" \"+ line\n",
    "                sections.append({})\n",
    "                sections[-1]['title'] = cur_sub_sub_main_sec\n",
    "                sections[-1]['content'] = \"\"\n",
    "            elif section_match.group(4):\n",
    "                cur_sub_main_sec = cur_main_sec +\" \"+ line\n",
    "                sections.append({})\n",
    "                sections[-1]['title'] = cur_sub_main_sec\n",
    "                sections[-1]['content'] = \"\"\n",
    "            elif section_match.group(3):\n",
    "                cur_main_sec = line\n",
    "                print(cur_main_sec)\n",
    "                sections.append({})\n",
    "                sections[-1]['title'] = cur_main_sec\n",
    "                sections[-1]['content'] = \"\"\n",
    "        for section in sections:\n",
    "            cleaned_content = text_formatter(section['content'])\n",
    "            len_content = len(cleaned_content)\n",
    "            \n",
    "            if len_content > seq_len:\n",
    "                cleaned_content = sentences_split(cleaned_content)\n",
    "            else:\n",
    "                cleaned_content = [cleaned_content]\n",
    "            for i in range (len(cleaned_content)):\n",
    "                pages_and_texts.append({\"char_count\": len(cleaned_content[i])+len(section['title']),\n",
    "                                        \"token_count\": (len(cleaned_content[i])+len(section['title'])) / 4,  # 1 token = ~4 chars\n",
    "                                        \"text\": f\"{section['title']}\\n {cleaned_content[i]}\"})\n",
    "                \n",
    "    return pages_and_texts\n",
    "\n",
    "# Đọc file và hiển thị kết quả\n",
    "file_path = \"D:\\CODE\\DA2\\Trợ lý ảo\\Documents\\Hướng dẫn\\Phương pháp lập Kế hoạch học tập.pdf\"\n",
    "pages_and_texts = split_section(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>7.25</td>\n",
       "      <td>\\n Điều 46. Quy định chuyển tiếp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294</td>\n",
       "      <td>73.50</td>\n",
       "      <td>1. Đối với các khoá tuyển sinh có quyết định c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464</td>\n",
       "      <td>116.00</td>\n",
       "      <td>2. Đối với các khoá tuyển sinh có quyết định c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436</td>\n",
       "      <td>109.00</td>\n",
       "      <td>2. Đối với các khoá tuyển sinh đã có quyết địn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464</td>\n",
       "      <td>116.00</td>\n",
       "      <td>3. Đối với các khoá tuyển sinh đã có quyết địn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  token_count                                               text\n",
       "0          29         7.25                   \\n Điều 46. Quy định chuyển tiếp\n",
       "1         294        73.50  1. Đối với các khoá tuyển sinh có quyết định c...\n",
       "2         464       116.00  2. Đối với các khoá tuyển sinh có quyết định c...\n",
       "3         436       109.00  2. Đối với các khoá tuyển sinh đã có quyết địn...\n",
       "4         464       116.00  3. Đối với các khoá tuyển sinh đã có quyết địn..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts_pd = pd.DataFrame(pages_and_texts)\n",
    "pages_and_texts_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
